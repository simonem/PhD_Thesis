# Related Works

The design of systems to support reflection benefits from research in the field of embodied interaction, because it provides the designers with tools to interact with information exploiting the affordances that ordinary object provide, while on- place, and preserving context cues when the information migrates between the physical (where it is generated and accessed) and the digital realms (where it is stored). Moreover it aims for extending the interaction to the background of the user’s attention allowing information to seamlessly move back and forth between users’ periphery and centre of attention, only when needed to trigger reflection.

## Embodied interaction

The design of systems to support interaction with embedded digital information benefits from research in the field of embodied interaction and tangible user interfaces (TUI). These research initiatives provide a theoretical background to create tools to interact with information exploiting the affordances that ordinary object provides, while being situated with the interaction object (e.g. a token), and aiming to preserve context cues when the information migrates between the physical (where it is generated and accessed) and the digital realms (where the information is stored). 

Embodied interaction, as defined by Dourish [@Dourish:2001vc], is a collection of a number of recent trends emerged in the Human-Computer interaction (HCI) field, relying on the common ground to provide a natural, native user interaction with information. During the first wave of computing, when the cost of computer-time was far higher than the cost of the person-time, users, mostly scientists, were interacting with mainframes with sequence commands given in assembler code, which were followed by a sequence of actions taken by the calculator. The user interaction paradigm was computer-friendly and human-understandable just for a few, the aim of that approach was to relieve the calculator from executing any superfluous tasks to the detriment of having users to employ their own time to do part of the calculation. Nowadays user interfaces have evolved from textual to graphical but often they still inherit that procedural way of operate, that sequence of commands-answers, based upon time.

Embodied interaction makes an enormous shift in the user interaction paradigm. Moving from time to space, it takes the interaction “off the screen” into the real world [@Dourish:2001vc], distributing input in space instead of time, de-sequentializing interaction and reducing the gap between where the information is created where it is accessed. Implementations of the embodied interaction paradigm are, for examples, the so-called tangible user interfaces (TUIs). Unlike GUIs, which manipulate elements virtually on-screen with the aid of the keyboard and mouse, TUIs integrates both representation and control of computation into physical artifacts [@krumm2009ubiquitous]. This approach allows system designers to be free to experiment with new type of metaphors, take advantage of the users physical skills and provide interfaces which exploit people’s knowledge and skills with the everyday, non-digital, world [@Jacob:2008vm]. Since the ways the manipulation of physical media profoundly differs from the manipulation of digital media [@Terrenghi:2007uv], metaphors adopted for the digital world need to be redesigned to meet physical affordances. A well-established field of research on TUIs is carried out by Hiroshi Ishii and colleagues at the MIT Media Lab, the aim of their project “Tangible Bits” is to make bits directly accessible using the real word objects as medium for interaction [@Ishii:1997ur].

Designing for embodied interaction it’s not just distributing the computation into the physical space, but it also entails moving from a sequential to a continuous interaction paradigm, shifting computers from a localized tool to a constant presence [@Abowd:2000jn]; hence having to deal with interruption and resumption of interaction, which is awkward when activities don’t have a clear start and end. Being the user-time a precious and constrained resource, information systems should require the full attention of the user only when needed. Today both desktop and mobile interfaces provide simple awareness cues by adding badges to icons showing for example the number of unread mails or number of agenda items. This approach still requires the user to focus her attention on a screen, even when not strictly necessary. A major shift in user interaction is to design interaction not just for the foreground but also for the background of user’s attention or, as defined by Mark Weiser, “design for the periphery” [@Weiser:1996vo].

According to Weiser [@Weiser:1996vo] design for the periphery is about calmly informing the user about background processes exploiting the cognitive ability of the human brain to focus on one foreground activity while monitoring changing data with subconscious processes; for example as we are aware of movements of people in a room without staring to them, the weather or the time of the day. A technology can be defined “calm” when it easily moves from the periphery of our attention, to the center, and back to the background only when needed, without overburdening the user. The work of Ishii and Ullmer’s research, described in [@Ishii:2008fh], takes steps towards Weiser’s vision defining foreground interaction as mediated by physical interfaces: graspable objects and augmented surfaces; while background interaction is mediated by ambient light, sounds and air. For example the ambientROOM project [@Ishii:1998:AIA:286498.286652] has prototyped a workspace where information such as notification of number of accesses to a webpage, weather or work activities are embedded in objects which notifies the users by changes in light colors, haptic feedbacks and sounds; for instance by reproducing sound of heavy rain in case of high number of access to a webpage. An important challenge tackled by ambientROOM is about how to give to information belonging to the digital domain an embodiment the user can recognize and link back to the digital source.

## Wearable computing, Augmented Reality and Token-based interaction

## Rapid prototyping, tools and techniques adopted
### Software prototyping 
### Hardware prototyping
### System integration and the cloud