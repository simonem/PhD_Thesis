\chapter{Results}\label{results}

\todo[inline]{Revision 2:\\ - updated authors' contributions description}

In the previous chapter the research background and methodology adopted during the work were presented. This chapter summarises the papers that added to the contributions of my work.

\section{Papers}\label{papers}

The research work has been published in two journal papers and four conference papers, one paper is currently ready for submission. In this section, papers that presents the results of this thesis are summarised. Each summary includes:
\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item Title 
	\item Authors and roles in the paper 
	\item Where the paper was published 
	\item A short description of the results 
	\item The paper's relation to research questions 
\end{itemize}

Each of the eight papers have been peer-reviewed. Papers are reprinted in full in Appendix \ref{papers} of the thesis.

In addition to the papers presented in this section this PhD work has produced fourteen peer-reviewed secondary papers presented in conferences and workshops which are omitted in this section. Those works present incremental achievements in research that lead to the results presented here. A brief description of secondary papers is included in Appendix \ref{secondary-papers}

\section[CroMAR: Mobile Augmented Reality for Supporting Reflection on Crowd Management]{Paper 1} \label{paper-1}

\emph{Title}: CroMAR: Mobile Augmented Reality for Supporting Reflection on Crowd Management

\emph{Authors}: Simone Mora, Alessandro Boron and Monica Divitini

\emph{Authors' contributions}: Mora led the research and the paper writing. He was actively involved in design, development, and evaluation of the system. Boron developed part of the described prototype and contributed to the paper with the description of the technical implementation. Divitini provided~general~supervision for the research and the paper writing.
\begin{quote}
	\emph{Abstract:} This paper discusses the usage of Mobile Augmented Reality (MAR) to support reflection on past events, using reflection on crowd management as scenario. Computer based support to reflection generally relies on the visualization of information connected to the experience one is reflecting upon. Different metaphors have been adopted to support easy access to relevant information within the reflection process, e.g., timelines and word clouds. In this context, MAR represents an interesting alternative because it can be used to promote reflection in the specific location of the event by augmenting it with relevant information. In this way, the authors can expect the reflection process to be grounded in a context that helps to make sense of the information and reflect on alternative paths of action. The paper presents the scenario of usage, together with the design, development, and evaluation of the prototype, CroMAR. Based on this experience, the authors identify challenges connected to the usage of Mobile Augmented Reality in terms of support for reflection, interaction, and design methodology. 
\end{quote}

\emph{Published in}: International Journal of Mobile Human Computer Interaction (IJMHCI), 2012

\emph{Description}: This paper investigates the adoption of Mobile Augmented Reality (MAR for short) to support debriefing of work practices that rely on management of resources in space. To date, it is the first time that MAR is used for such purpose. Crowd management, an activity typically performed by civil protection organisations during large public events, is scrutinised to investigate the use of augmented reality to support (collaborative) reflection processes after the event is concluded. Crowd management is a critical activity both for crisis preparedness and during crisis management.

CroMAR, an iPad app designed by the authors, demonstrated the use of MAR for reflection. The system developed focuses on supporting navigation of reflection-useful information along the time and space dimension. Visualisation of information is provided in-situ, in a physical context that helps making sense of the information and reflect on alternative paths of actions. Also, the system provides support in involving others in the reflection process and in sharing of its outcome.

The proposed design has been implemented in a working prototype for the iPad (Figure \ref{fig:cromar-prototype}), with focus on modularity and extensibility. The prototype has been evaluated in a focus group with experts. The study highlighted challenges in supporting reflective learning with MAR tools with focus on user experience. First the research required a better understanding of the conditions that makes MAR a better approach compared to other visualisation (e.g.~maps, timelines). Second, it claimed the need for providing scaffolding mechanisms to the reflection process; to make sure that relevant information for a given session is explored. Acknowledged by experts that the physical exploration of space provide scaffolding for exploration of information, it is necessary to study when it actually promotes reflection.
\begin{figure}
	[tbh] \centering 
	\includegraphics[width=1
	\textwidth]{cromar_1stproto} \caption{CroMAR early prototype} \label{fig:cromar-prototype} 
\end{figure}

During our evaluation, the overall user experience with the prototype was hampered by lack of functionalities and lack of suitable hardware platforms. The experience is disrupted by the lack of tools for filtering the data visualised, to remove redundant information and prioritise the important one. On the other side, the choice of iPads 2 has limitation due to device weight and size which can only be comfortably hold by the user for a few minutes.

The results from this paper have fed new design iterations for CroMAR. The design of new functionalities has followed more closely the guidelines provided by the CSRL model that was being developed. At the same time lighter and smaller version of the iPad came to the market which allowed an extended use for our system. A new prototype of CroMAR and its closer mapping to the CSRL model is described in P2.

\emph{Relation to the research questions: } The paper started the investigation of RQ2, ``How interaction techniques can be designed to facilitate the different phases of a reflection processes?'' \todo{update RQs}

\section[Supporting Debriefing with Sensor Data: A Reflective Approach to Crisis Training]{Paper 2}\label{paper-2}

\emph{Title:} Supporting Debriefing with Sensor Data: A Reflective Approach to Crisis Training

\emph{Authors:} Simone Mora and Monica Divitini

\emph{Authors' contributions:} Mora led the research and the paper writing. He also~lead the design of the~presented~technology and directly implemented or supervised the implementation of the prototypes. Both authors attended the evaluation studies.~Divitini provided~general~supervision for the research and the paper writing.
\begin{quote}
	\emph{Abstract:} In this paper we present our exploration into the use of sensor data to promote debriefing after training events simulating work experiences. In this way we address one of the core challenges of crisis training, namely the difficulty to exploit the full potential of training events, e.g.~during drills. The paper is theoretically grounded in the theory of reflective learning. The theoretical understanding is used for informing the design of WATCHiT, a wearable device for collecting sensor data during an event, and two applications for promoting debriefing in two different scenarios, CroMAR and Procedure Trainer. CroMAR supports disaster managers during in-situ debriefing after large events, while Procedure Trainer supports a team in reflecting after the simulation of a medical emergency procedure. The evaluation of the two applications shows that sensor data can be successfully used to support debriefing in both scenarios. Based on our experience, we draw lessons learned for the design of systems supporting debriefing in training events. 
\end{quote}

\emph{Published in:} Proceedings of Information Systems for Crisis Response and Management in Mediterranean Countries (ISCRAM-MED), 2014

\emph{Description:} The paper focuses on supporting with sensor data the activity of debriefing after training events simulating work experiences (e.g.~drills). To increase the efficacy of debriefing, and thus their impact on crisis preparedness, it is important to exploit the full potential of training events, which are costly to organise. Yet there are different forms of debriefing, all complex activities that may vary in terms of details and people involved according with the emergency scenario workers have been training on. Also debriefing is made difficult by the highly distributed nature of the work, the co-existence of different partial experiences and lack of data to complement human memories of the event. The paper addresses those challenges presenting an ecology of three applications of technology to assist two different debriefing scenarios. Two applications: \emph{CroMAR} and \emph{WATCHiT} have been described in P1 and P3 and are here presented in the last stage of their evolution. Trainer, introduced in this paper, is an smartphone application to support a quick reflection session on the implementation of protocols (e.g.~medical procedures) that can be done by the worker herself or in a team. The three applications have been evaluated during simulated crisis work events attended by the authors. In this work technology mapping with the CSRL model is made explicit.

The paper presets lesson learnt about the use of sensor data for supporting debriefing. They are derived from the authors experiences in building the systems and results from evaluations. Those propositions can be used by systems designers to create technologies both to capture and visualise data with the goal to better support reflection during debriefing.

\emph{First} it is acknowledged that sensor data has to be complemented by qualitative information in order to set the right focus for reflection and avoid over-sighting qualitative, yet critical aspects of the work that cannot be captured with technology.

\emph{Second} it suggests the use of \emph{visualisation} and \emph{storytelling} as mechanisms to promote sense-making processes for turning data into useful learning contents. Visualisation helps understanding the data by \emph{re-creating} a context that help spotting discrepancies with other source and, in turn, to trigger reflection. For this goal it is important that systems allow to compare data against a baseline or other source. Storytelling happens when a visualisation need to be interpreted and explained both to the self and to others, connecting data to the human memory of the event; as we observed during evaluations. Also, how to motivate the user in capturing data needed for visualisation and storytelling is still an open challenge.

\emph{Third}, the proposed technologies aim at bringing debriefings out of the traditional office setting but not as substituting, rather to complement the current practices by creating smooth transitions among different debriefing (and thus reflection) cycles. These propositions will guide future research to leverage sensor data in debriefings.

\emph{Relation to the research questions:} The paper covers aspects of RQ1 ``How computer interfaces can be designed to enable unobtrusive data collection during crisis work?'' and RQ2, ``How interaction techniques can be designed to facilitate the different phases of a reflection processes?''

\section[WATCHiT: a modular and wearable tool for data collection in crisis management and training]{Paper 3}\label{paper-3}

\emph{Title:} WATCHiT: a modular and wearable tool for data collection in crisis management and training

\emph{Authors:} Simone Mora and Monica Divitini

\emph{Authors' contributions:} Mora led the research and the paper writing.~He also presented the paper at the conference. Mora~directly implemented or supervised the implementation of the prototypes.~He also conducted the field studies and evaluations.~Divitini provided~general~supervision for the research and the paper writing.

\emph{Published in:} Proceedings of the European Conference in Ambient Intelligence (AMI), 2014
\begin{quote}
	\emph{Abstract:} We present WATCHiT, a prototype of sensor-augmented wristband computer for data collection during crisis response work. During crises, information about the environment (e.g.~to map the territory) and the rescuers (e.g.~for assessment of workers' condition) offers help to support coordination of work, post-emergency debriefing and to build realistic training scenarios. Being each crisis nearly unique it is important to collect data from every single occur- rence, yet it is difficult to foresee the type of data and context information that is relevant to capture. WATCHiT features: (1) wearable sensors, (2) easy customization of the type of information sensed, including both quantitative and qualitative data; (3) an intuitive, distraction-free user interface for controlling the data capturing procedure. Our design process has been driven by user studies during training events characterised by a high degree of realism; our prototype has been successfully evaluated with experts against technology acceptance. 
\end{quote}

\emph{Description:} This paper presents the design research that led the development of WATCHiT, a wearable computer for data collection in-action during crisis response work (Figure \ref{fig:watchit-prototypes}). The design research has followed four steps. Multiple user studies conducted by the authors have produced seven challenges for the design of technology tools to support data collection during real or simulated crisis.\todo{Add challenges table} User studies were performed during simulated work organised for training purposed. Simulations were organised to provide a high degree of realism, involving dozens of agents; and recreating working conditions as close as possible to real crises.

The drafted challenges highlight \emph{what} data is relevant to be captured and \emph{how} to collect it. The challenges aim at assisting the design of technology to capture data during crisis work; how the data is used is outside the scope of the paper. Yet data is essential to feed reflection during debriefings as well as helping coordination on the field and support decision-making process.

The challenges drove the design of WATCHiT by establishing three core requirements for the technology. WATHCiT must be implemented to be \emph{wearable} -to achieve the highest degree of mobility in sensing-, \emph{modular} -to allow customisation of the type of data captured to specific crisis scenarios-; finally it has to feature a \emph{distraction-free user interface} to disrupt as little as possible the work. The requirements were gradually implemented during three iterations. Three working prototypes were built (Figure \ref{fig:watchit-prototypes}). They feature a mix of software and hardware technology, an increased degree of wearability. Modularity is implemented as an architectural choice with physical sensor modules that allow for transient customisation of sensing capabilities and of the capability of the device to share data with third-party information systems. Indeed WATCHiT is a generic tool that acts as input interface and can be connected to several application logics.
\begin{figure}
	[tbh] \centering 
	\includegraphics[width=1
	\textwidth]{watchit_iterations} \caption{Three prototyping iterations for WATCHiT} \label{fig:watchit-prototypes} 
\end{figure}

The requirement for distraction-free user interfaces has been implemented with the creation of a novel interaction paradigm based on previous works on mnemonic body shortcuts and body-centric interaction {[}\textcite{Guerreiro:2008wt}; Chen:2012wk{]}. Those researches proposed to use areas of the body as shortcuts to trigger digital operations in the context to facilitate smartphone-mediated interaction with digital services. In this work body shortcuts are specialised to assist data capturing processes. Areas on work uniforms and tools (identified by RFID tags) trigger digital operation when the worker hover WATCHiT on. Each shortcut can be pre-configured to control the activation of specific sensors and to tag the data the is being captured with contextual information. User evaluations performed during physical simulations of crisis work have shown that the interaction technique is well accepted and WATCHiT is suitable to be used during simulated crisis work.

WATCHiT has been used to capture experiential data in order to feed technology assisted debriefings thanks to the integration with the CroMAR and Trainer app, as described in P2. A new prototype and summative evaluation for the tool is described in P6.

\emph{Relation to research questions:} The paper covers aspects of RQ1 ``How computer interfaces can be designed to enable unobtrusive data collection during crisis work?''

\section[Don't Panic: Enhancing Soft Skills for Civil Protection Workers]{Paper 4}\label{paper-4}

\emph{Title:} Don't Panic: Enhancing Soft Skills for Civil Protection Workers

\emph{Authors:} Ines Di Loreto, Simone Mora and Monica Divitini

\emph{Authors' contributions:} All the co-authors contributed to the research.~Di Loreto, first author, led the game design and coordinated the paper writing. Mora contributed to game design with his knowledge of crisis training. He also contributed to the documentation of the work in the paper.~Divitini provided~general~supervision for the research and the paper writing.

\emph{Published in:} Proceedings of the International Conference on Serious Games Development Applications (SGDA), 2012
\begin{quote}
	\emph{Abstract:} \emph{Don't Panic} is a serious game created to enhance soft skills in the crisis management field. The game is conceived to (i) add the fun element to training about stressful situations linked to panic management and (ii) teach skills such as communication styles, team management and coordination, time management, stress management and coping strategies. In this paper we present the first paper-based version of the game and its evaluation. The paper discusses the game design motivations, the methodological reasons behind its conception, and presents a pilot study. Results show that, even in its paper version, the game is a promising tool if linked with adequate and realistic procedures. This opens methodological questions about the role of computer based serious games. 
\end{quote}

\emph{Description:} The paper investigates the use of collaborative and mobile serious games as tools to enhance soft skills in crisis work. Serious games can complement traditional formal training by enhancing workers' communication abilities, stress management and coping skills. The fun element typical of (computer or traditional) games can act as motivation factor to engage workers in training. After presenting the state of the art of serious games for crisis training, the paper dives into the description of a board game designed by the authors, \emph{Don't Panic}. The game aims at training soft skills in the management of situations where diffusion of panic might put population at risk.

\emph{Don't Panic} is a cooperative board game inspired by Pandemic. Each player acts as a member of a panic control team that must work together to manage panicked crowds. During a game session different potential panicking events take place in the city represented on the board. Each player assumes a unique role within a team, with special abilities that improve the team's chances, if applied wisely. The players have a limited time to calm down the situation, before the panic will spread and they will lose the game. \emph{Don't Panic} has multiple aims linked to soft skills teaching and learning. The game aims at teaching communication styles useful to manage crisis events but also foster team building. The game was conceived to push local vs.~global reasoning, problem dissection and making plans dividing the board into zones and adding unpredictable events during the game that can create contrasting reasoning and priorities.

The paper details game mechanics and rules. A paper prototype of the game (Figure \ref{fig:dp-mockup}) is presented and evaluated in a pilot study with 10 civil protection experts who played the game. Building on evaluation results the authors derived implications for the design of a technology-augmented version of the game (described in P5).

The addition of technology in future iterations would release the players from doing game management tasks which disrupted the game experience in the paper mockup. Moreover it can be used to to add computer interactivity, for example by means of audio and graphic feedbacks. Secondly technology can improve learning effectiveness of the game by logging players' actions to be used as traces for reflection. After a game session, the captured traces can be used to help players reflect on the actions taken during the game, and to link those actions to their real work past experiences, with the goal of triggering \emph{storytelling} and therefore reflection.
\begin{figure}
	[tbh] \centering 
	\includegraphics[width=1
	\textwidth]{dp_mockup} \caption{Paper mockup of “Dont’ Panic!”} \label{fig:dp-mockup} 
\end{figure}

This pilot study and the derived implication for design have driven the design of an technology-enhanced version of the game presented in P5.

\emph{Relation to the research questions: } The paper contributes to the investigation of RQ2, ``How interaction techniques can be designed to facilitate the different phases of a reflection processes?''

\section[The interactive-token approach to board games]{Paper 5}\label{paper-5}

\emph{Title:} The interactive-token approach to board games

\emph{Authors:} Simone Mora, Ines Di Loreto and Monica Divitini

\emph{Authors' contributions:} Mora led the design and implementation work. He was also the~main~contributor of the paper. Di Loreto designed the board game that is used as example in the paper. Di Loreto and Mora jointly designed and attended evaluation studies.~Divitini provided~general~supervision for the research and the paper writing.

\emph{Published in:} Ready for submission
\begin{quote}
	\emph{Abstract:} Recent advances in interactive surfaces and Tangible User Interfaces have created a new interest in digital board games, aiming at mixing the benefits of traditional board games with the interactivity of video games. Within this strand of research we propose a new approach centred on the concepts of tokens, constraints, spatial expressions and interaction events. While mainstream solutions implement game interaction using interactive surfaces, our approach relies on physical manipulation of interactive objects on conventional surfaces. We illustrate the proposed approach by describing the design and development of a game for training of emergency workers. Building on feedbacks from user evaluation and our experience with the development, we outline design opportunities and challenges of the approach. 
\end{quote}

\emph{Description:} The paper presents a novel approach to the digitalisation of board games. The approach aims at adding computer games interactivity preserving board games's traditional social and physical affordances. Rather than implementing games for interactive surfaces (e.g.~touch-screens) the approach relies on the physical manipulation of interactive objects on conventional surfaces. After reviewing state of the art technology for digital board games, the approach is presented and grounded in existing frameworks of tangible user interfaces. To implement the approach into the design practice of digital board game a three-step process is presented. The process provides guidelines for designing computer-augmented game pieces and for mapping sensor-based interactions with pieces to game dynamics.

P4 introduced \emph{Don't Panic}, a serious game for enhancing soft skills for crisis workers, pointing out the role of technology as facilitator for generating engaging game experiences and for supporting post-game reflection and mapping with the real work. The approach and process presented in this paper have been used to drive a new design iteration for \emph{Don't Panic}. The new game shares the same game mechanics and learning objectives of \emph{Don't Panic}. The capability of the described approach to create games that preserve social affordances in terms of cooperations and prompts for discussions is functional to the serious role of the game as facilitator of storytelling and team building. Indeed players' interaction with technology during the game have been designed to promote discussions via extended visibility and simultaneous actions. At the same time the added computer interactivity provides a game experience which is more immersive and less disrupting compared to the paper mockup presented in P4. This allows for generating, by means of the game, a simulated work experience (management of panicking crowds) that re-create as much as possible conditions of emotional stress and decision making under time constraints, typical of real work. Beside the \emph{Don't Panic} result the approach itself is a contribution in the field of TUIs which can drive the digitalisation of serious or non-serious board games.

\emph{Don't Panic} has been implemented in a working prototype (Figure \ref{fig:dp-token}), expression of the technical challenges of building a complex system of sensor-based tangible user interfaces. A mix of software, hardware, laser-cut and 3D printing techniques have been orchestrated in order to fully implement game dynamics and produce a prototype of a game that can be played for an entire session without major disruptions.
\begin{figure}
	[tbh] \centering 
	\includegraphics[width=1
	\textwidth]{dp-multi} \caption{Technology-augmented “Don't Panic!” working prototype} \label{fig:dp-token} 
\end{figure}

The prototype has been evaluated against usability with 16 players who played the game in groups of four. Results from the experiment contribute in shedding the light on opportunities and challenges offered by the presented approach.

\emph{Relation to the research questions: } The paper contributes to the investigation of RQ2, ``HHow interaction techniques can be designed to facilitate the different phases of a reflection processes?'' and RQ3, ``How technology tools for supporting reflection can be rapid prototyped?''

\section[Context Becomes Content: Sensor Data for Computer-Supported Reflective Learning]{Paper 6}\label{paper-6}

\emph{Title:} Context Becomes Content: Sensor Data for Computer-Supported Reflective Learning

\emph{Authors:} Lars Müller, Monica Divitini, Simone Mora, Verónica Rivera-Pelayo and Wilhelm Stork

\emph{Authors' contributions:} Müller led the writing of the paper and contributed with one of the case studies. Mora designed the systems presented in the second case study. Mora also designed and conducted the evaluation of the system. Rivera-Pelayo contributed with state of the art about~the quantified self and to the methodological part. All the authors contributed to draw lessons learned and theoretical implications~from~the two~studies. Divitini and Stork contributed with supervision during the writing process.

\emph{Published in:} IEEE Transactions on Learning Technologies
\begin{quote}
	\emph{Abstract:} Wearable devices and ambient sensors can monitor a growing number of aspects of daily life and work. We propose to use this context data as content for learning applications in workplace settings to enable employees to reflect on experiences from their work. Learning by reflection is essential for today's dynamic work environments, as employees have to adapt their behaviour according to their experiences. Building on research on computer-supported reflective learning as well as persuasive technology, and inspired by the Quantified Self community, we present an approach to the design of tools supporting reflective learning at work by turning context information collected through sensors into learning content. The proposed approach has been implemented and evaluated with care staff in a care home and voluntary crisis workers. In both domains, tailored wearable sensors were designed and evaluated. The evaluations show that participants learned by reflecting on their work experiences based on their recorded context. The results highlight the potential of sensors to support learning from context data itself and outline lessons learned for the design of sensor-based capturing methods for reflective learning. 
\end{quote}

\emph{Description:} \todo{Shorten} This paper proposes the use of context data as content to support informal learning in workplace settings. An approach to the design of tools supporting reflective learning at work is presented. The approach uses technology to turn unstructured context data into learning contents. Two case studies presented in the paper demonstrated how the approach facilitates designers in mapping requirements from reflective learning theory with opportunities provided by technology, within the constraints of the specific workplace environment.

Three design decisions have to be made to turn context into content: \emph{what context} is relevant to be captured, \emph{how to capture} it and \emph{how to visualise} it to support reflection. The first two decisions were already explored in the design challenges for data capturing tools (P3). In this paper they are further elaborated.

The paper reveals that the decision of \emph{what context} to be captured is highly situated with the work experience to be acquired. The decision is made harder by the unpredictability of outcomes and lack of clear definition of learning goals, typical of informal learning; and by the subjectivity and need for interpretation required by the unstructured nature of context data. Yet the paper identifies three types of context that may include relevant data for reflection: task, affective and social. \emph{Task context} relates directly to the work process and is therefore easy to understand. \emph{Affective context} might work as a marker to recognise relevant episodes for reflection; because if something happens during the day, it will trigger an emotional reaction that can be captured with sensors. Finally \emph{social context} is important for many collaborative work practices since interactions with other people (colleague, customers, patients) constitute an important aspect of many experiences to reflect upon.

\emph{How to capture context} is also further elaborated in the paper. Three methods are proposed. Data can be \emph{self-reported} by the users, thus providing a subjective impression on an experience; for example by means of digital diaries. Data can be \emph{self-reported from third parties} in which an external perspective is made available to the reflecting person. Finally data den be captured \emph{automatically} by sensors and application; for example by means of stress or activity-tracking sensors.

Compared to P3 the paper adds a third design challenge connected to \emph{visualisation of context}. In order to be effective in triggering and sustaining a reflection sessions, data should be visualised from multiple perspective, depending on the criterion taken in account. Discrepancies among different view of the same experience should be outlined as reflection triggers. The social (comparing data over multiple users), spatial (the location data were captured) and historical perspective (evolution of data samples over time) are considered as effective for reflection. The CroMAR app (P1) and Trainer app (P2) were designed to visualise data according with one or more of those perspectives.

The three design dimensions are functional to build technology tools that implement the stages of the CSRL cycle (Chapter \ref{csrl}). While what context and how to capture it pertains designing of technology to support the \emph{plan and do work} stage of the model, \emph{how to visualise data} provides support for the subsequent stages of \emph{initiate reflection} and \emph{conduct reflection session} (Figure \ref{fig:csrl-mapping}). To motivate the user in the data collection process methods borrowed from persuasive technology and quantified self are presented.
\begin{figure}
	[tbh] \centering 
	\includegraphics[width=0.5
	\textwidth]{csrl_mapping} \caption{Design decisions to turn context into content, in relation to the CSRL model} \label{fig:csrl-mapping} 
\end{figure}

The paper further presents two case studies and their evaluation. One of the cases show the use of WATCHiT (P3) and Trainer (P2) to support reflection on the implementation of protocols (e.g.~medical procedures) by workers in the field, immediately after the procedure is performed. The system promotes a quick reflection session with easy triggers that can be done by the worker herself or collaboratively by a team. The second case study is an application designed to support carers in dementia care homes by reflecting on their daily interaction with residents and colleagues. Both case studies have target users -carers and crisis workers-, that work in highly dynamic environments and therefore benefit the most from on-the-job training.

The system evaluations presented in the two case studies show that participants were able to learn from the visualised context. Yet, it is confirmed that learning goals and expected outcomes are difficult to be defined a priori. During the design process of tools, it is critical to find a balance between defining an overall learning goal and providing a structured reflection session; versus a more open-ended one. It is also considered important to provide an option to record reflection outcomes, so that the gained insight can be user later (and might trigger new reflection cycles), as implemented in CroMAR (P1)

Capturing tools should be easy to adapt, in order to allows the users to deal with the unpredictability of relevance of the captured context. This has been implemented in WATCHiT (P3) by means of physical sensor modules.

\emph{Relation to the research questions: } The paper dresses RQ1 ``How computer interfaces can be designed to enable unobtrusive data collection during crisis work?'' and RQ2, ``How interaction techniques can be designed to facilitate the different phases of a reflection processes?''

\section[A Unified Architecture for Supporting Direct Tag-Based and Indirect Network-Based Resource Discovery]{Paper 7}\label{paper-7}

\emph{Title:} A Unified Architecture for Supporting Direct Tag-Based and Indirect Network-Based Resource Discovery

\emph{Authors:} Simone Mora and Babak Farshchian

\emph{Authors' contribution:} Mora conducted the design work and wrote the paper. Farshchian provided feedbacks throughout both the design and writing processes.~

\emph{Published in:} Proceedings of the European Conference on Ambient Intelligence (AMI), 2010
\begin{quote}
	\emph{Abstract:} Discovering and integrating ambient computational resources is a central topic in AmI. There are two major existing approaches: indirect network-based resource selection and direct tag-based resource identification. We motivate the need to integrate the two approaches through a scenario. We then present an architecture for a pluggable discovery system called UbiDisco. We demonstrate how UbiDisco implements a seamless integration of the two approaches at user interaction level through a framework for implementing discovery actions. 
\end{quote}

\emph{Description:} This paper presents a modular approach to software components for service discovery that blends the benefits of direct tag-based and indirect network-based discovery. The approach has been implemented in a middleware, called \emph{UbiDisco}, that allows for end-user discovery and customisation of computational resources and support data exchange between heterogeneous systems.

The work constitute a foundation of the rapid prototyping approach pursued in this PhD. As demonstrated in P2 and P6 the CSRL cycle is supported by a set of heterogeneous technology applications spanning from wearable and physical computers to apps for tablets and smartphones. Enable workers to easily link those tools in order to allow data exchange is critical to build custom, scenario-specific ecologies of tools to support reflection. For example in a maxi-emergency scenario multiple WATCHiTs (P3) can be connected to CroMAR (P1) to support on-site debriefing at the management level; while in weekly training activities the same WATCHiTs could be connected to Trainer (P2) to support multiple quick reflection sessions. Integrating different apps is technically complex since it involves serialisation of data, configuration of wireless networks and interaction of back-end services such as databases. From the perspective of the user it involves filling in configuration details. This activity might be very complex on mobile and wearable tools.

UbiDisco hinders the user from the complexity of configuring technical details by means of \emph{discovery actions}. The user can link two systems by reading a barcode or RFID tag which identifies the device/service and provide technical details for the configuration of the link. For example CroMAR running on a iPad can be linked to WATCHiT, by reading a barcode printed on the device hardware. In this way WATCHiT and CroMAR network addresses and protocols in use are exchanged between the two systems. WATCHiT becomes a data provider for CroMAR until a new \emph{discovery action} links WATCHiT to a new system (e.g.~another instance of CroMAR or Trainer).

\emph{Relation to the research questions: } The paper contributes to RQ3, ``How technology tools for supporting reflection can be rapid prototyped?'' 
